import backend.src.arya_parser
import backend.src.tokens
from backend.src import tokens, arya_parser
from backend.src.semantic_analyser import SemanticAnalyzer
from ply import lex


# source_code = '''
# func main() execute:
# {
#     h="hello";
#     w="world";
#     s=8;
#     g;
#
#     if(s>3) execute:
#         v = 3.4;
#         print (h, " ", w);
# }
# end_func'''

# source_code = """main_func execute:
#     {
#         print ( "Hello World!" ) ;
#     }
# end_func
# """

try:
    with open('test_code.txt', 'r') as file:
        # Read the contents of the file
        file_contents = file.read()
except FileNotFoundError:
    print("Error: The file 'test_code.txt' was not found.")


def arya_compiler(source_code):  # can call this in order to pass text to compiler
    # Build the lexer and pass it the source code
    lexer = lex.lex(module=tokens)
    lexer.input(str(source_code))

    # Print tokens generated by the lexer
    # for token in lexer:  # comment when not testing
    #     print(token)  # comment when not testing

    # Reset lexer for parser
    # lexer.input(source_code)  # comment when not testing

    # Parse the input
    parse_tree = arya_parser.parser.parse(lexer=lexer)
    print(parse_tree)

    # Create an instance of the semantic analyzer
    semantic_analyzer = SemanticAnalyzer()

    # Analyze the generated AST
    try:
        X = semantic_analyzer.analyze(parse_tree)
        # print(f"Semantic analysis successful.\n {X}")
        if X[1] is None:  # X[1] will only be !None if there are errors
            print(X[0])
            return X[0]
        else:  # if there are errors, return those only
            print(X[1])
            return X[1]
    except Exception as e:
        return f"Semantic analysis failed: \n {e}"

# compile(source_code)

# Pass the file contents to the compile function
arya_compiler(file_contents)
# arya_compiler(source_code)
